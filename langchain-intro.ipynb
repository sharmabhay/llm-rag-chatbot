{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ccf2c2-c96e-46f5-9f22-87160948745b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ised-openai-gpt4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\") # \"ised-openai-gpt4\"\n",
    "AZURE_ENDPOINT = os.getenv(\"AZURE_ENDPOINT\")\n",
    "AZURE_OPENAI_VERSION = os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    "\n",
    "print(AZURE_OPENAI_DEPLOYMENT_NAME)\n",
    "# print(AZURE_OPENAI_API_KEY)\n",
    "# print(AZURE_ENDPOINT)\n",
    "# print(AZURE_OPENAI_VERSION)\n",
    "\n",
    "# model_folder = \"/home/ubuntu/models/GGUF/\"\n",
    "# model_name = \"mistral-7b-instruct-v0.1.Q8_0.gguf\"\n",
    "# model_path = model_folder + model_name\n",
    "\n",
    "# n_gpu_layers = 42  # Change this value based on your model and your GPU VRAM pool.\n",
    "# n_batch = 1024  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "# n_ctx = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6088f516-284b-4b98-ab19-e3393cb7fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "# from langchain.llms import LlamaCpp\n",
    "\n",
    "# llm = LlamaCpp(\n",
    "#     model_path=model_path,\n",
    "#     temperature=0,\n",
    "#     max_tokens=4096,\n",
    "#     top_p=1,\n",
    "#     n_gpu_layers=n_gpu_layers,\n",
    "#     n_batch=n_batch,\n",
    "#     n_ctx= n_ctx\n",
    "# )\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=AZURE_OPENAI_VERSION,\n",
    "    openai_api_key=AZURE_OPENAI_API_KEY,\n",
    "    deployment_name=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    azure_endpoint=AZURE_ENDPOINT,\n",
    "    temperature=0,\n",
    "    streaming=True\n",
    "    # callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750817d7-2f75-4b96-9117-91f4feec8220",
   "metadata": {},
   "source": [
    "## Test LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f37d5c5-878d-458e-8b11-bf281824a0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First, we need to understand that the question is asking for the remainder when 139 is divided by 70. \\n\\nSo, we perform the division: 139 รท 70. \\n\\nThe quotient is 1 and the remainder is 69. \\n\\nTherefore, the remainder when 139 is divided by 70 is 69.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's work on the problem step by step to make sure we reach the correct solution.\"\"\"\n",
    "prompt2 = PromptTemplate.from_template(template)\n",
    "\n",
    "# llm.bind_tools([calculate])\n",
    "llm_chain = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "llm_chain.invoke(\"What is the remainder from 139 and 70?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798141b-6d22-4fa8-9086-2350b9a6dc05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
