{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9caf3807-e631-4a47-a3fa-6abb1fbc5dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "829"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(\"random_number\")\n",
    "def random_number_maker(input: str):\n",
    "    \"\"\"Returns a random number between 0-1000.\"\"\"\n",
    "    return random.randint(0, 1000)\n",
    "\n",
    "random_number_maker.run('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1866a2b5-4b4c-48b8-91e1-0d4497c823c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ised-openai-gpt4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\") # \"ised-openai-gpt4\"\n",
    "AZURE_ENDPOINT = os.getenv(\"AZURE_ENDPOINT\")\n",
    "AZURE_OPENAI_VERSION = os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    "\n",
    "print(AZURE_OPENAI_DEPLOYMENT_NAME)\n",
    "# print(AZURE_OPENAI_API_KEY)\n",
    "# print(AZURE_ENDPOINT)\n",
    "# print(AZURE_OPENAI_VERSION)\n",
    "\n",
    "# model_folder = \"/home/ubuntu/models/GGUF/\"\n",
    "# model_name = \"mistral-7b-instruct-v0.1.Q8_0.gguf\"\n",
    "# model_path = model_folder + model_name\n",
    "\n",
    "# n_gpu_layers = 42  # Change this value based on your model and your GPU VRAM pool.\n",
    "# n_batch = 1024  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "# n_ctx = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cc33606-36a5-4f55-b3d2-f0ed7b37f523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x75b3507759f0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x75b350777130>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='', streaming=True, azure_endpoint='https://ised-openai-model.openai.azure.com/openai/deployments/ised-openai-gpt4/chat/completions?api-version=2023-07-01-preview', deployment_name='ised-openai-gpt4', openai_api_version='2023-07-01-preview', openai_api_type='azure'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'random_number', 'description': 'Returns a random number between 0-1000.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'required': ['input']}}}]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "# from langchain.llms import LlamaCpp\n",
    "\n",
    "# llm = LlamaCpp(\n",
    "#     model_path=model_path,\n",
    "#     temperature=0,\n",
    "#     max_tokens=4096,\n",
    "#     top_p=1,\n",
    "#     n_gpu_layers=n_gpu_layers,\n",
    "#     n_batch=n_batch,\n",
    "#     n_ctx= n_ctx\n",
    "# )\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=AZURE_OPENAI_VERSION,\n",
    "    openai_api_key=AZURE_OPENAI_API_KEY,\n",
    "    deployment_name=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    azure_endpoint=AZURE_ENDPOINT,\n",
    "    temperature=0,\n",
    "    streaming=True\n",
    "    # callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "llm.bind_tools([random_number_maker])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63e9ec-1b51-469c-8bbc-f93be961f2a7",
   "metadata": {},
   "source": [
    "## Test LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd902df9-877a-4c5f-b55d-5d40f42f8717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the remainder from 139 and 70?', id='c2051f07-7291-4804-b525-17d5c2f288c2'),\n",
       " AIMessage(content='The remainder when you divide 139 by 70 is 69.', response_metadata={'finish_reason': 'stop'}, id='run-ac756cec-1e5f-4762-9386-d67b2546cda8-0')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import MessageGraph, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "graph_init = MessageGraph()\n",
    "\n",
    "graph_init.add_node(\"oracle\", llm)\n",
    "\n",
    "graph_init.add_edge(\"oracle\", END)\n",
    "\n",
    "graph_init.set_entry_point(\"oracle\")\n",
    "\n",
    "runnable = graph_init.compile()\n",
    "\n",
    "runnable.invoke(HumanMessage(content=\"What is the remainder from 139 and 70?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c73d6-8236-4658-bc46-406ef0f6b12d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
